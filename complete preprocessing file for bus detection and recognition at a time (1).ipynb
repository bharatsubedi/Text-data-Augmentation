{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## separate label and images after labelimg tool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_list = [file for file in os.listdir('test/') if file.endswith('.xml')]\n",
    "print(len(xml_list))\n",
    "label_dir ='label/'\n",
    "if not os.path.exists(label_dir):\n",
    "        os.mkdir(label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in xml_list:\n",
    "    shutil.move('test/'+i, 'label/'+i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert  ICDAR format from VOC format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "from typing import Dict\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "class XMLHandler:\n",
    "    def __init__(self, xml_path: str or Path):\n",
    "        self.xml_path = Path(xml_path)\n",
    "        self.root = self.__open()\n",
    "\n",
    "    def __open(self):\n",
    "        with self.xml_path.open() as opened_xml_file:\n",
    "            self.tree = ET.parse(opened_xml_file)\n",
    "            return self.tree.getroot()\n",
    "\n",
    "    def return_boxes_class_as_dict(self) -> Dict[int, Dict]:\n",
    "        boxes_dict = {}\n",
    "        for index, sg_box in enumerate(self.root.iter('object')):\n",
    "            boxes_dict[index] = {\"name\": sg_box.find(\"name\").text,\n",
    "                                 \"xmin\": int(sg_box.find(\"bndbox\").find(\"xmin\").text),\n",
    "                                 \"ymin\": int(sg_box.find(\"bndbox\").find(\"ymin\").text),\n",
    "                                 \"xmax\": int(sg_box.find(\"bndbox\").find(\"xmax\").text),\n",
    "                                 \"ymax\": int(sg_box.find(\"bndbox\").find(\"ymax\").text)}\n",
    "\n",
    "        return boxes_dict\n",
    "\n",
    "\n",
    "def converter(xml_files: str, output_folder: str) -> None:\n",
    "    xml_files = [file for file in os.listdir('json_to_voc') if file.endswith('.xml')]\n",
    "\n",
    "    for xml_index, xml in enumerate(xml_files):\n",
    "        print(xml)\n",
    "        file_name = xml[:-4]\n",
    "        filename = \"{}.txt\".format(file_name)\n",
    "        \n",
    "        filename_path = Path(output_folder) / filename\n",
    "        xml_content = XMLHandler('json_to_voc/'+xml)\n",
    "        boxes = xml_content.return_boxes_class_as_dict()\n",
    "\n",
    "        with open(filename_path, \"a\") as file:\n",
    "            for box_index in boxes:\n",
    "                box = boxes[box_index]\n",
    "                if box['name']=='-':\n",
    "                    continue\n",
    "                print(box['name'])\n",
    "                box_content = f\"{box['name']} {box['xmin']} {box['ymin']} {box['xmax']} {box['ymax']}\\n\"\n",
    "                file.write(box_content)\n",
    "\n",
    "    print(f\"Converted {len(xml_files)} files!\")\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    XML_FOLDER = \"json_to_voc/\"\n",
    "    OUTPUT_FOLDER =  \"icdar\"\n",
    "    if not os.path.exists('icdar/'):\n",
    "        os.mkdir('icdar/')\n",
    "    converter(XML_FOLDER, OUTPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CRNN format changing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [file for file in os.listdir('icdar') if file.endswith('.txt')]\n",
    "print(len(file_list))\n",
    "if not os.path.exists('images/'):\n",
    "        os.mkdir('images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "from PIL import Image\n",
    "with open('train.txt','w') as f:\n",
    "    for i in file_list:\n",
    "        img_name = i[:-4]\n",
    "        name = img_name+'.jpg'\n",
    "        with open('icdar/'+i,'r') as a:\n",
    "            lines = a.read().splitlines()\n",
    "            for j in lines:\n",
    "                line = j.split(' ')\n",
    "                im = Image.open('JPEGImages/'+name)\n",
    "                area = (int(line[1]), int(line[2]), int(line[3]), int(line[4]))\n",
    "                cropped_im = im.crop(area)\n",
    "                final_name = 'images/{}_{}.jpg'.format(line[0],str(n))\n",
    "                cropped_im.save(final_name, quality=100, optimize=True)\n",
    "                f.write('{}{}{}'.format(final_name,' ',line[0]))\n",
    "                f.write('\\n')\n",
    "                n=n+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data augmentation for bus number detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_brightness(img, value=10):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "    lim = 255 - value\n",
    "    v[v > lim] = 255\n",
    "    v[v <= lim] += value\n",
    "    final_hsv = cv2.merge((h, s, v))\n",
    "    img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy(noise_typ,image):\n",
    "    if noise_typ == \"gauss\":\n",
    "        row,col,ch= image.shape\n",
    "        mean = 0\n",
    "        var = 0.1\n",
    "        sigma = var**0.5\n",
    "        gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
    "        gauss = gauss.reshape(row,col,ch)\n",
    "        noisy = image + gauss\n",
    "        return noisy\n",
    "    elif noise_typ == \"s&p\":\n",
    "        row,col,ch = image.shape\n",
    "        s_vs_p = 0.5\n",
    "        amount = 0.004\n",
    "        out = np.copy(image)\n",
    "        # Salt mode\n",
    "        num_salt = np.ceil(amount * image.size * s_vs_p)\n",
    "        coords = [np.random.randint(0, i - 1, int(num_salt))for i in image.shape]\n",
    "        out[coords] = 1\n",
    "        # Pepper mode\n",
    "        num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n",
    "        coords = [np.random.randint(0, i - 1, int(num_pepper))for i in image.shape]\n",
    "        out[coords] = 0\n",
    "        return out\n",
    "    elif noise_typ == \"poisson\":\n",
    "        vals = len(np.unique(image))\n",
    "        vals = 2 ** np.ceil(np.log2(vals))\n",
    "        noisy = np.random.poisson(image * vals) / float(vals)\n",
    "        return noisy\n",
    "    elif noise_typ ==\"speckle\":\n",
    "        row,col,ch = image.shape\n",
    "        gauss = np.random.randn(row,col,ch)\n",
    "        gauss = gauss.reshape(row,col,ch)        \n",
    "        noisy = image + image * gauss\n",
    "        return noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur(src):\n",
    "    dst = cv2.GaussianBlur(src,(3,3),cv2.BORDER_DEFAULT)\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast(img):\n",
    "    alpha = 1.5 # Contrast control (1.0-3.0)\n",
    "    beta = 0 # Brightness control (0-100)\n",
    "\n",
    "    adjusted = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "    return adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motion_horizontal_blur(img):\n",
    "    size = randrange(1, 3)\n",
    "    # generating the horizontal kernel\n",
    "    kernel_motion_blur = np.zeros((size, size))\n",
    "    kernel_motion_blur[int((size-1)/2), :] = np.ones(size)\n",
    "    kernel_motion_blur = kernel_motion_blur / size\n",
    "\n",
    "    # applying the kernel to the input image\n",
    "    output = cv2.filter2D(img, -1, kernel_motion_blur)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def motion_vertical_blur(img):\n",
    "#     size = randrange(1, 5)\n",
    "#     kernel_motion_blur = np.zeros((size, size))\n",
    "#     kernel_motion_blur[int(:, (size-1)/2)] = np.ones(size)\n",
    "#     kernel_motion_blur = kernel_motion_blur / size\n",
    "#     # applying the kernel to the input image\n",
    "#     output = cv2.filter2D(img, -1, kernel_motion_blur)\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('daimg/'):\n",
    "    os.mkdir('daimg/')\n",
    "if not os.path.exists('dalabel/'):\n",
    "    os.mkdir('dalabel/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagelist = [file for file in os.listdir('JPEGImages/') if file.endswith('.jpg')]\n",
    "print(len(imagelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randrange, uniform\n",
    "num = 1\n",
    "for img in imagelist:\n",
    "    img_name = img[:-4]\n",
    "    img = cv2.imread(\"JPEGImages/{}\".format(img))\n",
    "    txt_name = img_name+'.txt'\n",
    "    # adding noise\n",
    "    blur_img=True\n",
    "    brightness =True\n",
    "    noise = True\n",
    "    #contrast_ratio =True\n",
    "    #motion_blur_hori=True\n",
    "    with open('dalabel/'+str(num)+'.txt','w') as df:\n",
    "        with open('icdar/'+txt_name,'r') as nf:\n",
    "            line = nf.read()\n",
    "            df.write(line)\n",
    "            cv2.imwrite(\"daimg/{}{}\".format(num,'.jpg'),img)\n",
    "            num=num+1\n",
    "    if motion_blur_hori:\n",
    "        motion_img = motion_horizontal_blur(img)\n",
    "        with open('dalabel/'+str(num)+'_motion'+'.txt','w') as df:\n",
    "            with open('icdar/'+txt_name,'r') as nf:\n",
    "                line = nf.read()\n",
    "                df.write(line)\n",
    "                cv2.imwrite(\"daimg/{}_motion{}\".format(num,'.jpg'),motion_img)\n",
    "                num=num+1\n",
    "#     if contrast_ratio:\n",
    "#         cont_img =contrast(img)\n",
    "#         with open('dalabel/'+str(num)+'_contrast'+'.txt','w') as df:\n",
    "#             with open('icdar/'+txt_name,'r') as nf:\n",
    "#                 line = nf.read()\n",
    "#                 df.write(line)\n",
    "#                 cv2.imwrite(\"daimg/{}_contrast{}\".format(num,'.jpg'),cont_img)\n",
    "#                 num=num+1\n",
    "    if brightness:  \n",
    "        bri = increase_brightness(img)     \n",
    "        with open('dalabel/'+str(num)+'_brightness'+'.txt','w') as df:\n",
    "            with open('icdar/'+txt_name,'r') as nf:\n",
    "                line = nf.read()\n",
    "                df.write(line)\n",
    "                cv2.imwrite(\"daimg/{}_brightness{}\".format(num,'.jpg'),bri)\n",
    "                num=num+1\n",
    "#     if blur_img:  \n",
    "#         b_img = blur(img)     \n",
    "#         with open('dalabel/'+str(num)+'_blur'+'.txt','w') as df:\n",
    "#             with open('icdar/'+txt_name,'r') as nf:\n",
    "#                 line = nf.read()\n",
    "#                 df.write(line)\n",
    "#                 cv2.imwrite(\"daimg/{}_blur{}\".format(num,'.jpg'),b_img)\n",
    "#                 num=num+1\n",
    "            \n",
    "    if noise:\n",
    "        noi = ['s&p','gauss','s&p']\n",
    "        n = np.random.choice(noi,1,replace = False)\n",
    "        noise_sp = noisy(n,img)\n",
    "        with open('dalabel/'+str(num)+'_noise'+'.txt','w') as df:\n",
    "            with open('icdar/'+txt_name,'r') as nf:\n",
    "                line = nf.read()\n",
    "                df.write(line)\n",
    "                cv2.imwrite(\"daimg/{}_noise{}\".format(num,'.jpg'),noise_sp)\n",
    "                num=num+1   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data augmentation for bus number recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from random import randrange, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_images = 'images/'\n",
    "imagelist = [file for file in os.listdir(crop_images) if file.endswith('.jpg')]\n",
    "print(len(imagelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_brightness(img, value=30):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "    lim = 255 - value\n",
    "    v[v > lim] = 255\n",
    "    v[v <= lim] += value\n",
    "    final_hsv = cv2.merge((h, s, v))\n",
    "    img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motion_horizontal_blur(img):\n",
    "    size = randrange(1, 3)\n",
    "    # generating the horizontal kernel\n",
    "    kernel_motion_blur = np.zeros((size, size))\n",
    "    kernel_motion_blur[int((size-1)/2), :] = np.ones(size)\n",
    "    kernel_motion_blur = kernel_motion_blur / size\n",
    "\n",
    "    # applying the kernel to the input image\n",
    "    output = cv2.filter2D(img, -1, kernel_motion_blur)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast(img):\n",
    "    alpha = 1.5 # Contrast control (1.0-3.0)\n",
    "    beta = 0 # Brightness control (0-100)\n",
    "\n",
    "    adjusted = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "    return adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy(noise_typ,image):\n",
    "    if noise_typ == \"gauss\":\n",
    "        row,col,ch= image.shape\n",
    "        mean = 0\n",
    "        var = 0.1\n",
    "        sigma = var**0.5\n",
    "        gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
    "        gauss = gauss.reshape(row,col,ch)\n",
    "        noisy = image + gauss\n",
    "        return noisy\n",
    "    elif noise_typ == \"s&p\":\n",
    "        row,col,ch = image.shape\n",
    "        s_vs_p = 0.5\n",
    "        amount = 0.004\n",
    "        out = np.copy(image)\n",
    "        # Salt mode\n",
    "        num_salt = np.ceil(amount * image.size * s_vs_p)\n",
    "        coords = [np.random.randint(0, i - 1, int(num_salt))for i in image.shape]\n",
    "        out[coords] = 1\n",
    "        # Pepper mode\n",
    "        num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n",
    "        coords = [np.random.randint(0, i - 1, int(num_pepper))for i in image.shape]\n",
    "        out[coords] = 0\n",
    "        return out\n",
    "    elif noise_typ == \"poisson\":\n",
    "        vals = len(np.unique(image))\n",
    "        vals = 2 ** np.ceil(np.log2(vals))\n",
    "        noisy = np.random.poisson(image * vals) / float(vals)\n",
    "        return noisy\n",
    "    elif noise_typ ==\"speckle\":\n",
    "        row,col,ch = image.shape\n",
    "        gauss = np.random.randn(row,col,ch)\n",
    "        gauss = gauss.reshape(row,col,ch)        \n",
    "        noisy = image + image * gauss\n",
    "        return noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur(src):\n",
    "    dst = cv2.GaussianBlur(src,(5,5),cv2.BORDER_DEFAULT)\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('R_daimg/'):\n",
    "    os.mkdir('R_daimg/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 1\n",
    "with open('train_da.txt','w') as df:\n",
    "    with open('train.txt','r') as rd:\n",
    "        abc = rd.readjson_list=[file for file in os.listdir('json/') if file.endswith('.json')]\n",
    "print(len(json_list))\n",
    "if not os.path.exists('json_to_voc'):\n",
    "    os.makedirs('json_to_voc')().splitlines()       \n",
    "        for img1 in abc:\n",
    "            img = img1.split(' ')\n",
    "            print(img[0])\n",
    "            ab =img[1]\n",
    "            img = cv2.imread(\"{}\".format(img[0]))\n",
    "            blur_img=True\n",
    "            brightness =True\n",
    "            noise = True\n",
    "            contrast_ratio =True\n",
    "            motion_blur_hori=True\n",
    "            if motion_blur_hori:\n",
    "                motion_img = motion_horizontal_blur(img)\n",
    "                cv2.imwrite(\"R_daimg/{}{}\".format(num,'.jpg'),motion_img)\n",
    "                df.write(\"images/{}{}{}{}\".format(num,'.jpg',' ',ab))\n",
    "                df.write('\\n')\n",
    "                num=num+1\n",
    "            if contrast_ratio:\n",
    "                cont_img =contrast(img)\n",
    "                cv2.imwrite(\"R_daimg/{}{}\".format(num,'.jpg'),cont_img)\n",
    "                df.write(\"images/{}{}{}{}\".format(num,'.jpg',' ',ab))\n",
    "                df.write('\\n')\n",
    "                num=num+1\n",
    "            if brightness:  \n",
    "                bri = increase_brightness(img)     \n",
    "                cv2.imwrite(\"R_daimg/{}{}\".format(num,'.jpg'),bri)\n",
    "                df.write(\"images/{}{}{}{}\".format(num,'.jpg',' ',ab))\n",
    "                df.write('\\n')\n",
    "                num=num+1\n",
    "            if blur_img:  \n",
    "                b_img = blur(img)     \n",
    "                cv2.imwrite(\"R_daimg/{}{}\".format(num,'.jpg'),b_img)\n",
    "                df.write(\"images/{}{}{}{}\".format(num,'.jpg',' ',ab))\n",
    "                df.write('\\n')\n",
    "                num=num+1\n",
    "\n",
    "            if noise:\n",
    "                noi = ['s&p','gauss','s&p']\n",
    "                n = np.random.choice(noi,1,replace = False)\n",
    "                noise_sp = noisy(n,img)\n",
    "                cv2.imwrite(\"R_daimg/{}{}\".format(num,'.jpg'),noise_sp)\n",
    "                df.write(\"images/{}{}{}{}\".format(num,'.jpg',' ',ab))\n",
    "                df.write('\\n')\n",
    "                num=num+1   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICDar to YoLOv5 conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pickle\n",
    "import os\n",
    "import cv2\n",
    "from os import listdir, getcwd\n",
    "from os.path import join\n",
    "\n",
    "\n",
    "def convert(size, box):\n",
    "    dw = 1./size[0]\n",
    "    dh = 1./size[1]\n",
    "    x = (box[0] + box[1])/2.0\n",
    "    y = (box[2] + box[3])/2.0\n",
    "    w = box[1] - box[0]\n",
    "    h = box[3] - box[2]\n",
    "    x = x*dw\n",
    "    w = w*dw\n",
    "    y = y*dh\n",
    "    h = h*dh\n",
    "    return (round(x,5),round(y,5),round(w,5),round(h,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_txt_folder = 'dalabel/'\n",
    "aug_img_folder = 'daimg/'\n",
    "Yolo_txt_folder = 'Y_dalabel/'\n",
    "dalabel_list = [file for file in os.listdir(aug_txt_folder) if file.endswith('.txt')]\n",
    "print(len(dalabel_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(Yolo_txt_folder):\n",
    "    os.mkdir(Yolo_txt_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in dalabel_list:\n",
    "#     y_img=cv2.imread(aug_img_folder+i[:-4]+'.jpg')\n",
    "#     h, w = y_img.shape[:2]\n",
    "#     in_file = open(aug_txt_folder+i,'r')\n",
    "#     out_file = open(Yolo_txt_folder+i, 'w')\n",
    "#     line = in_file.read().splitlines()\n",
    "#     print(line)\n",
    "#     for obj1 in line:\n",
    "#         obj =obj1.split(' ')\n",
    "#         b = (float(obj[1]), float(obj[3]), float(obj[2]), float(obj[4]))\n",
    "#         bb = convert((w,h), b)\n",
    "#         out_file.write(str(0) + \" \" + \" \".join([str(a) for a in bb]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiple object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dalabel_list:\n",
    "    y_img=cv2.imread(aug_img_folder+i[:-4]+'.jpg')\n",
    "    h, w = y_img.shape[:2]\n",
    "    in_file = open(aug_txt_folder+i,'r')\n",
    "    out_file = open(Yolo_txt_folder+i, 'w')\n",
    "    line = in_file.read().splitlines()\n",
    "    string ='0123456789AB'\n",
    "    str_list=list(string)\n",
    "    #print(len(string))\n",
    "    print(line)\n",
    "    for obj1 in line:\n",
    "        obj =obj1.split(' ')\n",
    "        b = (float(obj[1]), float(obj[3]), float(obj[2]), float(obj[4]))\n",
    "        bb = convert((w,h), b)\n",
    "        str_val = str_list.index(str(obj[0]))\n",
    "        print(str_val)\n",
    "        out_file.write(str(str_val) + \" \" + \" \".join([str(a) for a in bb]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert voc to yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pickle\n",
    "import os\n",
    "from os import listdir, getcwd\n",
    "from os.path import join\n",
    "\n",
    "def convert(size, box):\n",
    "    dw = 1./size[0]\n",
    "    dh = 1./size[1]\n",
    "    x = (box[0] + box[1])/2.0\n",
    "    y = (box[2] + box[3])/2.0\n",
    "    w = box[1] - box[0]\n",
    "    h = box[3] - box[2]\n",
    "    x = x*dw\n",
    "    w = w*dw\n",
    "    y = y*dh\n",
    "    h = h*dh\n",
    "    return (round(x,5),round(y,5),round(w,5),round(h,5))\n",
    "\n",
    "def convert_annotation(image_id):\n",
    "    in_file = open('label/%s.xml'%(image_id))\n",
    "    out_file = open('labels/%s.txt'%( image_id), 'w')\n",
    "    tree=ET.parse(in_file)\n",
    "    root = tree.getroot()\n",
    "    size = root.find('size')\n",
    "    w = int(size.find('width').text)\n",
    "    h = int(size.find('height').text)\n",
    "\n",
    "    for obj in root.iter('object'):\n",
    "        difficult = obj.find('difficult').text\n",
    "        xmlbox = obj.find('bndbox')\n",
    "        b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text), float(xmlbox.find('ymin').text), float(xmlbox.find('ymax').text))\n",
    "        bb = convert((w,h), b)\n",
    "        out_file.write(str(0) + \" \" + \" \".join([str(a) for a in bb]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('labels/'):\n",
    "    os.makedirs('labels/')\n",
    "image_ids = [file for file in os.listdir('JPEGImages/') if file.endswith('.jpg')]\n",
    "list_file = open('trainval.txt', 'w')\n",
    "for image_ids in image_ids:\n",
    "    image_id = image_ids[:-4]\n",
    "    list_file.write('JPEGImages/%s.jpg\\n'%(image_id))\n",
    "    convert_annotation(image_id)\n",
    "list_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### some more things to add for boosting performance of object detection\n",
    "#https://blog.gofynd.com/boost-object-detection-model-accuracy-552586d698c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JPEGImages/GPJ442_122.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def unwarp(img, src, dst, testing):\n",
    "    h, w = img.shape[:2]\n",
    "    # use cv2.getPerspectiveTransform() to get M, the transform matrix, and Minv, the inverse\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    # use cv2.warpPerspective() to warp your image to a top-down view\n",
    "    warped = cv2.warpPerspective(img, M, (w, h), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    if testing:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "        f.subplots_adjust(hspace=.2, wspace=.05)\n",
    "        ax1.imshow(img)\n",
    "        x = [src[0][0], src[2][0], src[3][0], src[1][0], src[0][0]]\n",
    "        y = [src[0][1], src[2][1], src[3][1], src[1][1], src[0][1]]\n",
    "        ax1.plot(x, y, color='red', alpha=0.4, linewidth=3, solid_capstyle='round', zorder=2)\n",
    "        ax1.set_ylim([h, 0])\n",
    "        ax1.set_xlim([0, w])\n",
    "        ax1.set_title('Original Image', fontsize=30)\n",
    "        ax2.imshow(cv2.flip(warped, 1))\n",
    "        ax2.set_title('Unwarped Image', fontsize=30)\n",
    "        plt.show()\n",
    "    else:\n",
    "        return warped, M\n",
    "\n",
    "\n",
    "im = cv2.imread(\"GPJ442_122.jpg\")\n",
    "\n",
    "w, h = im.shape[0], im.shape[1]\n",
    "# We will first manually select the source points \n",
    "# we will select the destination point which will map the source points in\n",
    "# original image to destination points in unwarped image\n",
    "src = np.float32([(20,     1),\n",
    "                  (540,  130),\n",
    "                  (20,    520),\n",
    "                  (570,  450)])\n",
    "\n",
    "dst = np.float32([(600, 0),\n",
    "                  (0, 0),\n",
    "                  (600, 531),\n",
    "                  (0, 531)])\n",
    "\n",
    "unwarp(im, src, dst, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('GPJ442_122.jpg')\n",
    "rows,cols,ch = img.shape\n",
    "\n",
    "pts1 = np.float32([[360,50],[2122,470],[2264, 1616],[328,1820]])\n",
    "\n",
    "ratio=1.6\n",
    "cardH=math.sqrt((pts1[2][0]-pts1[1][0])*(pts1[2][0]-pts1[1][0])+(pts1[2][1]-pts1[1][1])*(pts1[2][1]-pts1[1][1]))\n",
    "cardW=ratio*cardH;\n",
    "pts2 = np.float32([[pts1[0][0],pts1[0][1]], [pts1[0][0]+cardW, pts1[0][1]], [pts1[0][0]+cardW, pts1[0][1]+cardH], [pts1[0][0], pts1[0][1]+cardH]])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "\n",
    "offsetSize=500\n",
    "transformed = np.zeros((int(cardW+offsetSize), int(cardH+offsetSize)), dtype=np.uint8);\n",
    "dst = cv2.warpPerspective(img, M, transformed.shape)\n",
    "\n",
    "plt.subplot(121),plt.imshow(img),plt.title('Input')\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Output')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Open a typical 24 bit color image. For this kind of image there are\n",
    "# 8 bits (0 to 255) per color channel\n",
    "img = cv2.imread('mandrill.png')  # mandrill reference image from USC SIPI\n",
    "\n",
    "s = 128\n",
    "img = cv2.resize(img, (s,s), 0, 0, cv2.INTER_AREA)\n",
    "\n",
    "def apply_brightness_contrast(input_img, brightness = 0, contrast = 0):\n",
    "    \n",
    "    if brightness != 0:\n",
    "        if brightness > 0:\n",
    "            shadow = brightness\n",
    "            highlight = 255\n",
    "        else:\n",
    "            shadow = 0\n",
    "            highlight = 255 + brightness\n",
    "        alpha_b = (highlight - shadow)/255\n",
    "        gamma_b = shadow\n",
    "        \n",
    "        buf = cv2.addWeighted(input_img, alpha_b, input_img, 0, gamma_b)\n",
    "    else:\n",
    "        buf = input_img.copy()\n",
    "    \n",
    "    if contrast != 0:\n",
    "        f = 131*(contrast + 127)/(127*(131-contrast))\n",
    "        alpha_c = f\n",
    "        gamma_c = 127*(1-f)\n",
    "        \n",
    "        buf = cv2.addWeighted(buf, alpha_c, buf, 0, gamma_c)\n",
    "\n",
    "    return buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('GPJ442_122.jpg')\n",
    "\n",
    "alpha = 1.5 # Contrast control (1.0-3.0)\n",
    "beta = 0 # Brightness control (0-100)\n",
    "\n",
    "adjusted = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "\n",
    "# cv2.imshow('original', image)\n",
    "# cv2.imshow('adjusted', adjusted)\n",
    "# cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copyimport cv2\n",
    "import numpy as np\n",
    "image = cv2.imread(\"GPJ442_122.jpg\")\n",
    "\n",
    "alpha=1.5\n",
    "beta=20\n",
    "\n",
    "new_image=cv2.addWeighted(image,alpha,np.zeros(image.shape, image.dtype),0,beta)\n",
    "\n",
    "# cv2.imshow(\"new\",new_image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply vertical and horizental motion blur\n",
    "#https://stackoverflow.com/questions/40305933/how-to-add-motion-blur-to-numpy-array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from random import randrange, uniform\n",
    "\n",
    "# randrange gives you an integral value\n",
    "size = randrange(1, 5)\n",
    "print(size)\n",
    "img = cv2.imread('GPJ442_122.jpg')\n",
    "cv2.imshow('Original', img)\n",
    "\n",
    "# generating the kernel\n",
    "kernel_motion_blur = np.zeros((size, size))\n",
    "kernel_motion_blur[int((size-1)/2), :] = np.ones(size)\n",
    "kernel_motion_blur = kernel_motion_blur / size\n",
    "\n",
    "# applying the kernel to the input image\n",
    "output = cv2.filter2D(img, -1, kernel_motion_blur)\n",
    "\n",
    "cv2.imshow('Motion Blur', output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#size - in pixels, size of motion blur\n",
    "#angel - in degrees, direction of motion blur\n",
    "def apply_motion_blur(image, size, angle):\n",
    "    k = np.zeros((size, size), dtype=np.float32)\n",
    "    k[ (size-1)// 2 , :] = np.ones(size, dtype=np.float32)\n",
    "    k = cv2.warpAffine(k, cv2.getRotationMatrix2D( (size / 2 -0.5 , size / 2 -0.5 ) , angle, 1.0), (size, size) )  \n",
    "    k = k * ( 1.0 / np.sum(k) )        \n",
    "    return cv2.filter2D(image, -1, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### voc data batch processing for changing label name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# : Batch modify the label name of the xml tag file in the VOC data set\n",
    "def changelabelname(inputpath):\n",
    "    listdir = os.listdir(inputpath)\n",
    "    for file in listdir:\n",
    "        if file.endswith('xml'):\n",
    "            file = os.path.join(inputpath,file)\n",
    "            tree = ET.parse(file)\n",
    "            root = tree.getroot()\n",
    "            for object1 in root.findall('object'):\n",
    "                for sku in object1.findall('name'):           #Find the name you need to modify\n",
    "                    if (sku.text == sku.text):               #‘preName’ is the name before the modification\n",
    "                        sku.text = 'route'                 #‘TESTNAME’ is the modified name\n",
    "                        tree.write(file,encoding='utf-8')     #Write into the original xml file and avoid the original xml Chinese characters garbled\n",
    "                    else:\n",
    "                        pass\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    inputpath = 'label'  # \n",
    "    changelabelname(inputpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### icdar to voc format converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from os.path import join\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from pascal_voc_writer import Writer\n",
    "if not os.path.exists('voc_label'):\n",
    "    os.makedirs('voc_label')\n",
    "\n",
    "\n",
    "def convert_fn(txt_name):\n",
    "    with open(f'ground_truth/{txt_name}') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        xml_name=txt_name[:-4]\n",
    "        img_name=txt_name[:-4]+'.jpg'\n",
    "        path = 'test/'+img_name\n",
    "        img = cv2.imread(path)\n",
    "        h, w, _ = img.shape\n",
    "        writer = Writer(img_name, w, h)\n",
    "        for line in lines:\n",
    "            lis= line.split(' ')\n",
    "            writer.addObject(lis[0], lis[1], lis[2], lis[3], lis[4])\n",
    "        writer.save(f'voc_label/{xml_name}.xml')\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_list = [file for file in os.listdir('ground_truth/') if file.endswith('.txt')]\n",
    "print(len(txt_list))\n",
    "for i in txt_list:\n",
    "    convert_fn(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Json format to voc format conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pascal_voc_writer import Writer\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list=[file for file in os.listdir('json/') if file.endswith('.json')]\n",
    "print(len(json_list))\n",
    "if not os.path.exists('json_to_voc'):\n",
    "    os.makedirs('json_to_voc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in json_list:\n",
    "    img_name=i[:-5]+'.jpg'\n",
    "    img_path='JPEGImages/'+img_name\n",
    "    xml_name=i[:-5]+'.xml'\n",
    "    img=cv2.imread(img_path)\n",
    "    height, width, channels = img.shape\n",
    "    writer= Writer(img_path,width,height)\n",
    "    with open('json/'+i) as json_file:\n",
    "        json_list=json.load(json_file)['shapes']\n",
    "        for data in json_list:\n",
    "            label=data['label']\n",
    "            cords=data['points']\n",
    "            xmin,ymin,xmax,ymax=int(cords[0][0]),int(cords[0][1]),int(cords[1][0]),int(cords[1][1])\n",
    "            writer.addObject(label,xmin,ymin,xmax,ymax)\n",
    "    writer.save('json_to_voc/'+xml_name)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# move validation data into different folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "if not os.path.exists('Val_JPEGimages'):\n",
    "    os.makedirs('Val_JPEGimages')\n",
    "if not os.path.exists('Val_icdar'):\n",
    "    os.makedirs('Val_icdar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('val.txt') as f:\n",
    "    lines =f.read().splitlines()\n",
    "    for line in lines:\n",
    "        li = line.split('/')\n",
    "        ori_img_path=line\n",
    "        img_name=li[1]\n",
    "        icdar=li[1]\n",
    "        icdar_name=icdar[:-4]+'.txt'\n",
    "        icdar_path='Val_icdar/'+icdar_name\n",
    "        ori_icdar_path='icdar/'+icdar_name\n",
    "        img_path='Val_JPEGimages/'+img_name\n",
    "        shutil.move(ori_img_path,img_path)\n",
    "        shutil.move(ori_icdar_path,icdar_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
